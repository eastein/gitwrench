#!/usr/bin/env python

import sys
import os, os.path
import time
import json
import subprocess
import git
import pprint
import re

HEADS_EXPR = re.compile('^([0-9a-f]+)\trefs/heads/(.*)$')

class UnknownBranchException(Exception) :
	pass

class UnknownGitProblem(Exception) :
	pass

def getcommit(branch) :
	p = subprocess.Popen(['git', 'log', '-1', branch], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
	out, err = p.communicate()
	status = p.wait()
	if status != 0 :
		raise UnknownBranchException
	line1 = out.split('\n')[0]
	if not line1.startswith('commit ') :
		raise UnknownGitProblem

	return line1[7:]

def cache_filename() :
	return os.path.join(os.path.expanduser('~'), '.gitwrench')

def readcache() :
	try :
		return json.load(open(cache_filename()))
	except :
		return dict()

def writecache(cache) :
	json.dump(cache, open(cache_filename(), 'w'))

def getremotehead(branch, local_head, origin_head, cache, max_cache_sec=None) :
	path = os.path.abspath(os.getcwd())
	ret = None
	# we are using caches and such things exist for this branch
	if max_cache_sec is not None and path in cache and branch in cache[path] :
		ts, cached_local_head, cached_origin_head, hash = cache[path][branch]
		# the local stuff hasn't changed at all
		if cached_local_head == local_head and cached_origin_head == origin_head :
			# and it's not expired!
			if time.time() - max_cache_sec < ts :
				# then we can use this.
				ret = hash

	if ret is None :
		ret = _getremotehead(branch)

	cache.setdefault(path, dict())
	cache[path][branch] = (time.time(), local_head, origin_head, ret)

	return ret

def _getremotehead(branch) :
	p = subprocess.Popen(['git', 'ls-remote', '--heads', 'origin'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
	out, err = p.communicate()
	status = p.wait()
	# TODO handle remote host unavailable / stuff like that well.
	if status != 0 :
		print 'failed to get remote head in %s' % os.getcwd()
		raise UnknownGitProblem
	if err :
		raise UnknownGitProblem

	heads = {}

	for l in out.split('\n') :
		m = HEADS_EXPR.match(l)
		if m :
			h, b = m.groups(1)
			heads[b] = h
	
	if branch in heads :
		return heads[branch]

INIT = 3
LOCAL = 1
UNSYNC = 2
OK = 0
UNCOM = 4

NAMES = {
	INIT : "initial",
	LOCAL : "local",
	UNSYNC : "unsync",
	OK : "ok",
	UNCOM : "uncom"
}

MAX_NAME = max([len(n) for n in NAMES.values()])

def analyze(path, cache, expiry) :
	os.chdir(path)

	repo = git.repo.Repo('.')

	status = {}

	def add_status(st, msg) :
		status.setdefault(st, list())
		status[st] = msg

	# TODO check for untracked files

	try :
		local_master = getcommit('master')
	except :
		add_status(INIT, 'has no master')
		return status

	try :
		# TODO option to not check remote git servers (causes slowdown)
		origin_master = getcommit('origin/master')
		remote_master = getremotehead('master', local_master, origin_master, cache, max_cache_sec=expiry)

		if local_master == origin_master and origin_master == remote_master:
			add_status(OK, 'is synchronized')
		elif local_master != origin_master and origin_master != remote_master:
			add_status(UNSYNC, 'has diverged (git pull, git push)')
		elif remote_master != origin_master :
			add_status(UNSYNC, 'is behind (git pull)')
		else :
			add_status(UNSYNC, 'is ahead (git push)')
	except UnknownBranchException :
		try :
			git_svn = getcommit('git-svn')

			if local_master == git_svn :
				add_status(OK, 'is not ahead')
			else :
				add_status(UNSYNC, 'unpushed (git svn dcommit)')
		except :
			add_status(LOCAL, 'has no origin/master or git-svn')

	if repo.is_dirty :
		add_status(UNCOM, 'dirty')

	return status

def walk_dir(path, expiry) :
	dirs = os.listdir(path)
	dirs.sort()
	
	results = []

	def cm(a, b) :
		return int.__cmp__(max(a[1].keys()), max(b[1].keys()))

	longest_path = 0

	cache = readcache()
	try :
		for sp in dirs :
			p = os.path.join(path, sp)
			if os.path.isdir(p) and os.path.exists(os.path.join(p, '.git')) :
				results.append((p, analyze(p, cache, expiry)))
				longest_path = max(longest_path, len(p))
	finally :
		writecache(cache)

	results.sort(cmp=cm)

	for path, analysis in results :
		keyword = NAMES[max(analysis.keys())]
		keyword += ' '*(MAX_NAME - len(keyword))
		path += ' '*(longest_path - len(path))
		print '%s %s %s' % (keyword, path, ' / '.join(analysis.values()))

if __name__ == '__main__' :
	expiry = 1800
	try :
		p = os.path.abspath(sys.argv[1])

		try :
			expiry = int(sys.argv[2])
		except IndexError :
			pass
	except :
		sys.stderr.write('usage: gitwrench <path> [seconds_cache_expiry]\n')
		sys.exit(1)

	walk_dir(p, expiry)
