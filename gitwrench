#!/usr/bin/env python

import sys
import os, os.path
import time
import json
import subprocess
import git
import pprint
import re
import optparse
from concurrent import futures

CONCURRENCY = 20
HEADS_EXPR = re.compile('^([0-9a-f]+)\trefs/heads/(.*)$')

class UnknownBranchException(Exception) :
	pass

class UnknownGitProblem(Exception) :
	pass

class RemoteNetworkErrorException(Exception) :
	pass

class EncryptedLinkMITMException(Exception) :
	pass

class NoNetworkOpsException(Exception) :
	pass

def getcommit(branch) :
	p = subprocess.Popen(['git', 'log', '-1', branch], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
	out, err = p.communicate()
	status = p.wait()
	if status != 0 :
		raise UnknownBranchException
	line1 = out.split('\n')[0]
	if not line1.startswith('commit ') :
		raise UnknownGitProblem

	return line1[7:]

def cache_filename() :
	return os.path.join(os.path.expanduser('~'), '.gitwrench')

def readcache() :
	try :
		return json.load(open(cache_filename()))
	except :
		return dict()

def writecache(cache) :
	json.dump(cache, open(cache_filename(), 'w'))

def getremotehead(branch, local_head, origin_head, cache, max_cache_sec=None, network_ops_ok=True) :
	path = os.path.abspath(os.getcwd())
	ret = None
	# we are using caches and such things exist for this branch
	if max_cache_sec is not None and path in cache and branch in cache[path] :
		ts, cached_local_head, cached_origin_head, hash = cache[path][branch]
		# the local stuff hasn't changed at all
		if cached_local_head == local_head and cached_origin_head == origin_head :
			# and it's not expired!
			if time.time() - max_cache_sec < ts :
				# then we can use this.
				ret = hash

	if ret is None :
		if network_ops_ok :
			ret = _getremotehead(branch)
		else :
			raise NoNetworkOpsException

	cache.setdefault(path, dict())
	cache[path][branch] = (time.time(), local_head, origin_head, ret)

	return ret

def all_in(los, s) :
	return reduce(lambda x,y: x and y, [los_ in s for los_ in los])

def _getremotehead(branch) :
	p = subprocess.Popen(['git', 'ls-remote', '--heads', 'origin'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
	out, err = p.communicate()
	status = p.wait()

	if status != 0 or err :
		if 'Connection timed out' in err or 'Network is unreachable while accessing' in err or 'Name or service not known' in err or 'Couldn\'t resolve host' in err or 'The remote end hung up unexpectedly' in err :
			raise RemoteNetworkErrorException
		# the below are fun examples of exactly how I know airline wifi is built by jackholes.
		if 'Operation now in progress while accessing' in err :
			raise RemoteNetworkErrorException
		ssl_problems = ['error: SSL: certificate subject name', 'does not match target host name']
		if all_in(ssl_problems, out) or all_in(ssl_problems, err) :
			raise EncryptedLinkMITMException("ssl certificate name mismatch")

		print err
		raise UnknownGitProblem

	heads = {}

	for l in out.split('\n') :
		m = HEADS_EXPR.match(l)
		if m :
			h, b = m.groups(1)
			heads[b] = h
	
	if branch in heads :
		return heads[branch]

UNK = 0
OK = 1
LOCAL = 2
UNSYNC = 3
INIT = 4
UNCOM = 5

NAMES = {
	INIT : "initial",
	LOCAL : "local",
	UNSYNC : "unsync",
	OK : "ok",
	UNCOM : "uncom",
	UNK : "unknown"
}

MAX_NAME = max([len(n) for n in NAMES.values()])

def analyze(path, cache, expiry, network_ops_ok) :
	os.chdir(path)

	repo = git.repo.Repo('.')

	status = {}

	def add_status(st, msg) :
		status.setdefault(st, list())
		status[st].append(msg)

	# TODO check for untracked files

	try :
		local_master = getcommit('master')
	except :
		add_status(INIT, 'has no master')
		return status

	try :
		# TODO option to not check remote git servers (causes slowdown)
		origin_master = getcommit('origin/master')
		try :
			remote_master = getremotehead('master', local_master, origin_master, cache, max_cache_sec=expiry, network_ops_ok=network_ops_ok)
		except NoNetworkOpsException :
			# fake that the data was checked, when it wasn't
			remote_master = origin_master
		except RemoteNetworkErrorException :
			# fake that the data was checked, when it wasn't
			remote_master = origin_master
			add_status(UNK, 'remote data may be stale')
		except EncryptedLinkMITMException, elme :
			# fake that the data was checked, when it wasn't
			remote_master = origin_master
			add_status(UNK, '%s - remote data may be stale' % elme.msg())

		if local_master == origin_master and origin_master == remote_master:
			add_status(OK, 'is synchronized')
		elif local_master != origin_master and origin_master != remote_master:
			add_status(UNSYNC, 'has diverged (git pull, git push)')
		elif remote_master != origin_master :
			add_status(UNSYNC, 'is behind (git pull)')
		else :
			add_status(UNSYNC, 'is ahead (git push)')
	except UnknownBranchException :
		try :
			git_svn = getcommit('git-svn')

			if local_master == git_svn :
				add_status(OK, 'is not ahead')
			else :
				add_status(UNSYNC, 'unpushed (git svn dcommit)')
		except :
			add_status(LOCAL, 'has no origin/master or git-svn')
	
	dirtycheck = repo.is_dirty
	if callable(dirtycheck) :
		dirtycheck = dirtycheck()

	if dirtycheck :
		add_status(UNCOM, 'dirty')

	return status

def walk_dir(path, expiry, network_ops_ok=True, concurrency=CONCURRENCY) :
	dirs = os.listdir(path)
	dirs.sort()
	
	results = []

	def cm(a, b) :
		return int.__cmp__(max(a[1].keys()), max(b[1].keys()))

	longest_path = 0

	cache = readcache()
	try :
		tp = futures.ProcessPoolExecutor(max_workers=concurrency)

		for sp in dirs :
			p = os.path.join(path, sp)
			if os.path.isdir(p) and os.path.exists(os.path.join(p, '.git')) :
				results.append((p, tp.submit(analyze, p, cache, expiry, network_ops_ok=network_ops_ok)))
				longest_path = max(longest_path, len(p))
	finally :
		writecache(cache)

	completed_results = list()
	for path, analysis in results :
		completed_results.append((path, analysis.result()))

	del tp

	completed_results.sort(cmp=cm)

	for path, analysis in completed_results :
		keyword = NAMES[max(analysis.keys())]
		keyword += ' '*(MAX_NAME - len(keyword))
		path += ' '*(longest_path - len(path))
		print '%s %s %s' % (keyword, path, ' / '.join([', '.join(v) for v in analysis.values()]))

if __name__ == '__main__' :
	parser = optparse.OptionParser()
	parser.add_option('-e', '--expiry', dest='expiry', default=1800, help="Number of seconds to wait before the cached remote heads for a repository are re-checked.")
	parser.add_option('-n', '--no-network', dest='no_network', default=False, action='store_true', help="When enabled, do not do any network operations.")
	parser.add_option('-c', '--concurrency', dest='concurrency', default=CONCURRENCY, help="How many simultaneous operations to perform.")
	(options, args) = parser.parse_args()

	try :
		p = os.path.abspath(args[0])
	except :
		p = os.getcwd()

	expiry = int(options.expiry)
	assert expiry >= 0
	network_ops_ok = not options.no_network
	
	walk_dir(p, expiry, network_ops_ok=network_ops_ok)
