#!/usr/bin/env python

import sys
import os, os.path
import time
import json
import subprocess
import git
import pprint
import re
import optparse
from concurrent import futures

CONCURRENCY = 20
HEADS_EXPR = re.compile('^([0-9a-f]+)\trefs/heads/(.*)$')

class UnknownBranchException(Exception) :
	pass

class UnknownGitProblem(Exception) :
	pass

class RemoteNetworkErrorException(Exception) :
	pass

class EncryptedLinkMITMException(Exception) :
	pass

class NoNetworkOpsException(Exception) :
	pass

def getcommit(branch) :
	p = subprocess.Popen(['git', 'log', '-1', branch], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
	out, err = p.communicate()
	status = p.wait()
	if status != 0 :
		raise UnknownBranchException
	line1 = out.split('\n')[0]
	if not line1.startswith('commit ') :
		raise UnknownGitProblem

	return line1[7:]

def cache_filename() :
	return os.path.join(os.path.expanduser('~'), '.gitwrench')

def readcache() :
	try :
		return json.load(open(cache_filename()))
	except :
		return dict()

def writecache(cache) :
	json.dump(cache, open(cache_filename(), 'w'))

def getremotehead(branch, local_head, origin_head, cache, max_cache_sec=None, network_ops_ok=True) :
	path = os.path.abspath(os.getcwd())
	ret = None
	# we are using caches and such things exist for this branch
	if max_cache_sec is not None and path in cache and branch in cache[path] :
		ts, cached_local_head, cached_origin_head, hash = cache[path][branch]
		# the local stuff hasn't changed at all
		if cached_local_head == local_head and cached_origin_head == origin_head :
			# and it's not expired!
			if time.time() - max_cache_sec < ts :
				# then we can use this.
				ret = hash

	if ret is None :
		if network_ops_ok :
			ret = _getremotehead(branch)
		else :
			raise NoNetworkOpsException

	cache.setdefault(path, dict())
	cache[path][branch] = (time.time(), local_head, origin_head, ret)

	return ret

def all_in(los, s) :
	return reduce(lambda x,y: x and y, [los_ in s for los_ in los])

def _getremotehead(branch) :
	p = subprocess.Popen(['git', 'ls-remote', '--heads', 'origin'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
	out, err = p.communicate()
	status = p.wait()

	if status != 0 or err :
		if 'Connection timed out' in err or 'Network is unreachable while accessing' in err or 'Name or service not known' in err or 'Couldn\'t resolve host' in err or 'The remote end hung up unexpectedly' in err :
			raise RemoteNetworkErrorException
		# the below are fun examples of exactly how I know airline wifi is built by jackholes.
		if 'Operation now in progress while accessing' in err :
			raise RemoteNetworkErrorException
		ssl_problems = ['error: SSL: certificate subject name', 'does not match target host name']
		if all_in(ssl_problems, out) or all_in(ssl_problems, err) :
			raise EncryptedLinkMITMException("ssl certificate name mismatch")

		print err
		raise UnknownGitProblem

	heads = {}

	for l in out.split('\n') :
		m = HEADS_EXPR.match(l)
		if m :
			h, b = m.groups(1)
			heads[b] = h
	
	if branch in heads :
		return heads[branch]

UNK = 0
OK = 1
LOCAL = 2
UNSYNC = 3
INIT = 4
UNCOM = 5

# DST = desync type
DST_GB = 0 # git behind
DST_GA = 1 # git ahead
DST_GSB = 2 # git-svn behind
DST_GSA = 3 # git-svn ahead

NAMES = {
	INIT : "initial",
	LOCAL : "local",
	UNSYNC : "unsync",
	OK : "ok",
	UNCOM : "uncom",
	UNK : "unknown"
}

MAX_NAME = max([len(n) for n in NAMES.values()])

def analyze(path, cache, expiry, network_ops_ok) :
	os.chdir(path)

	repo = git.repo.Repo('.')

	status = {}
	status_additional = {}

	def add_status(st, msg, a=None) :
		status.setdefault(st, list())
		status[st].append(msg)
		if a is not None :
			status_additional.setdefault(st, list())
			if not isinstance(a, list) :
				a = [a]
			status_additional[st] += a

	# TODO check for untracked files

	try :
		local_master = getcommit('master')
	except :
		add_status(INIT, 'has no master')
		return status, status_additional

	try :
		# TODO option to not check remote git servers (causes slowdown)
		origin_master = getcommit('origin/master')
		try :
			remote_master = getremotehead('master', local_master, origin_master, cache, max_cache_sec=expiry, network_ops_ok=network_ops_ok)
		except NoNetworkOpsException :
			# fake that the data was checked, when it wasn't
			remote_master = origin_master
		except RemoteNetworkErrorException :
			# fake that the data was checked, when it wasn't
			remote_master = origin_master
			add_status(UNK, 'remote data may be stale')
		except EncryptedLinkMITMException, elme :
			# fake that the data was checked, when it wasn't
			remote_master = origin_master
			add_status(UNK, '%s - remote data may be stale' % elme.msg())

		if local_master == origin_master and origin_master == remote_master:
			add_status(OK, 'is synchronized')
		elif local_master != origin_master and origin_master != remote_master:
			add_status(UNSYNC, 'has diverged (git pull, git push)', a=[DST_GB, DST_GA])
		elif remote_master != origin_master :
			add_status(UNSYNC, 'is behind (git pull)', a=DST_GB)
		else :
			add_status(UNSYNC, 'is ahead (git push)', a=DST_GA)
	except UnknownBranchException :
		try :
			git_svn = getcommit('git-svn')

			if local_master == git_svn :
				add_status(OK, 'is not ahead')
			else :
				add_status(UNSYNC, 'unpushed (git svn dcommit)', a=DST_GSA)

			# TODO check remote SVN head
		except :
			add_status(LOCAL, 'has no origin/master or git-svn')
	
	dirtycheck = repo.is_dirty
	if callable(dirtycheck) :
		dirtycheck = dirtycheck()

	if dirtycheck :
		add_status(UNCOM, 'dirty')

	return status, status_additional

def executor(path, argv) :
	os.chdir(path)
	return path, argv, subprocess.call(argv)

def walk_dir(path, expiry, network_ops_ok=True, concurrency=CONCURRENCY, push=False, pull=False, summary=False) :
	dirs = os.listdir(path)
	dirs.sort()
	
	results = []

	def cm(a, b) :
		return int.__cmp__(max(a[1].keys()), max(b[1].keys()))

	longest_path = 0

	cache = readcache()
	try :
		tp = futures.ProcessPoolExecutor(max_workers=concurrency)

		for sp in dirs :
			p = os.path.join(path, sp)
			if os.path.isdir(p) and os.path.exists(os.path.join(p, '.git')) :
				results.append((p, tp.submit(analyze, p, cache, expiry, network_ops_ok=network_ops_ok)))
				longest_path = max(longest_path, len(p))
	finally :
		writecache(cache)

	completed_results = list()
	for path, analysis in results :
		completed_results.append(tuple([path] + list(analysis.result())))

	# get additional statuses (usable flags for push/pull needs and base technology)
	additional_statuses = [(r[0], r[2]) for r in completed_results if r[2]]

	# we only want normal statuses for output.
	completed_results = [(r[0],r[1]) for r in completed_results]
	completed_results.sort(cmp=cm)

	for path, analysis in completed_results :
		keyword = NAMES[max(analysis.keys())]
		keyword += ' '*(MAX_NAME - len(keyword))
		path += ' '*(longest_path - len(path))
		print '%s %s %s' % (keyword, path, ' / '.join([', '.join(v) for v in analysis.values()]))

	work = list()

	for p, a in additional_statuses :
		if len(a.keys()) == 1 and UNSYNC in a :
			if a[UNSYNC] == [DST_GA] and push :
				work.append(tp.submit(executor, p, ['git', 'push']))
			elif a[UNSYNC] == [DST_GB] and pull :
				work.append(tp.submit(executor, p, ['git', 'pull']))
			elif a[UNSYNC] == [DST_GSA] and push :
				work.append(tp.submit(executor, p, ['git', 'svn', 'dcommit']))
			elif a[UNSYNC] == [DST_GSB] and pull :
				work.append(tp.submit(executor, p, ['git', 'svn', 'rebase']))

	work_outputs = list()

	for w in work :
		p, argv, rcode = w.result()
		if rcode != 0 :
			work_outputs.append('%s $ %s -> FAILED %d' % (p, ' '.join(argv), rcode))
		else :
			if summary :
				work_outputs.append("%s $ %s -> SUCCESS" % (p, ' '.join(argv)))
	del tp

	if work :
		if not work_outputs :
			print 'gitwrench: all %d remote operation(s) successful.' % len(work)

		if work_outputs :
			for wo in work_outputs :
				print 'gitwrench: %s' % wo

if __name__ == '__main__' :
	parser = optparse.OptionParser()
	parser.add_option('-e', '--expiry', dest='expiry', default=1800, help="Number of seconds to wait before the cached remote heads for a repository are re-checked.")
	parser.add_option('-n', '--no-network', dest='no_network', default=False, action='store_true', help="When enabled, do not do any network operations.")
	parser.add_option('-c', '--concurrency', dest='concurrency', default=CONCURRENCY, help="How many simultaneous operations to perform.")
	parser.add_option('--push', dest='push', action='store_true', default=False, help="Push non-diverged git/git-svn local copies that are ahead to upstream.")
	parser.add_option('--pull', dest='pull', action='store_true', default=False, help="Pull non-diverged git/git-svn local copies that are behind from upstream.")
	parser.add_option('-s', dest='summary', action='store_true', default=True, help="For use with action commands. Summarize actions taken at the end.")
	(options, args) = parser.parse_args()

	try :
		p = os.path.abspath(args[0])
	except :
		p = os.getcwd()

	expiry = int(options.expiry)
	assert expiry >= 0
	network_ops_ok = not options.no_network
	
	walk_dir(p, expiry, network_ops_ok=network_ops_ok, push=options.push, pull=options.pull, summary=options.summary)
